{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMenUG3AyPo1g8VafCrXSUp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/willpanderson/AdventuresInPython/blob/master/best.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4TSmAiXh0Yn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import matplotlib.pylab as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import traceback\n",
        "import textwrap\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1wn9x4LJjrV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.set_option(\"display.precision\", 8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsGFcrzNJol4",
        "colab_type": "code",
        "outputId": "8323a610-ac72-41c0-e749-522695c19e6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yoj_IN7hJrxo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_root='/content/drive/My Drive/TFLITE/car_images'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvf21iFmJt5E",
        "colab_type": "code",
        "outputId": "f4357378-f60b-402a-f122-ea8f348d4c04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "IMAGE_SHAPE = (224, 224)\n",
        "TRAINING_DATA_DIR = str(data_root)\n",
        "print(TRAINING_DATA_DIR);\n",
        "datagen_kwargs = dict(rescale=1./255, validation_split=.20)\n",
        "valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**datagen_kwargs)\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "TRAINING_DATA_DIR,\n",
        "subset=\"validation\",\n",
        "shuffle=True,\n",
        "target_size= IMAGE_SHAPE\n",
        ")\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**datagen_kwargs)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "TRAINING_DATA_DIR,\n",
        "subset=\"training\",\n",
        "shuffle=True,\n",
        "target_size=IMAGE_SHAPE)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/TFLITE/car_images\n",
            "Found 472 images belonging to 6 classes.\n",
            "Found 1904 images belonging to 6 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbZscgt4Jwti",
        "colab_type": "code",
        "outputId": "f34337f4-4c89-40fd-bafd-11c0d8c56035",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "image_batch_train, label_batch_train = next(iter(train_generator))\n",
        "print(\"Image batch shape: \", image_batch_train.shape)\n",
        "print(\"Label batch shape: \", label_batch_train.shape)\n",
        "dataset_labels = sorted(train_generator.class_indices.items(), key=lambda pair:pair[1])\n",
        "dataset_labels = np.array([key.title() for key, value in dataset_labels])\n",
        "print(dataset_labels)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Image batch shape:  (32, 224, 224, 3)\n",
            "Label batch shape:  (32, 6)\n",
            "['Convertible' 'Coupe' 'Sedan' 'Suv' 'Truck' 'Van']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBmp0PZhJ00D",
        "colab_type": "code",
        "outputId": "739cfa80-34bc-4009-a896-c56d7932a2c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\",\n",
        "output_shape=[1280],\n",
        "trainable=False),\n",
        "tf.keras.layers.Dropout(0.4),\n",
        "tf.keras.layers.Dense(train_generator.num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.build([None, 224, 224, 3])\n",
        "model.summary()\n",
        "model.compile(\n",
        "optimizer=tf.keras.optimizers.Adam(),\n",
        "loss='categorical_crossentropy',\n",
        "metrics=['acc'])"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "keras_layer_2 (KerasLayer)   multiple                  2257984   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              multiple                  7686      \n",
            "=================================================================\n",
            "Total params: 2,265,670\n",
            "Trainable params: 7,686\n",
            "Non-trainable params: 2,257,984\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F092fSqoJ3ww",
        "colab_type": "code",
        "outputId": "eca6d53a-744c-493d-fc8d-bac0dbf5bc53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "steps_per_epoch = np.ceil(train_generator.samples/train_generator.batch_size)\n",
        "val_steps_per_epoch = np.ceil(valid_generator.samples/valid_generator.batch_size)\n",
        "hist = model.fit(\n",
        "train_generator,\n",
        "epochs=10,\n",
        "verbose=1,\n",
        "steps_per_epoch=steps_per_epoch,\n",
        "validation_data=valid_generator,\n",
        "validation_steps=val_steps_per_epoch).history\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "60/60 [==============================] - ETA: 0s - loss: 1.2840 - acc: 0.4879"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "60/60 [==============================] - 23s 391ms/step - loss: 1.2840 - acc: 0.4879 - val_loss: 0.7956 - val_acc: 0.7161\n",
            "Epoch 2/10\n",
            "60/60 [==============================] - 23s 386ms/step - loss: 0.7932 - acc: 0.7001 - val_loss: 0.6208 - val_acc: 0.7691\n",
            "Epoch 3/10\n",
            "60/60 [==============================] - 23s 389ms/step - loss: 0.6674 - acc: 0.7474 - val_loss: 0.6110 - val_acc: 0.7818\n",
            "Epoch 4/10\n",
            "54/60 [==========================>...] - ETA: 1s - loss: 0.5639 - acc: 0.8027"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERPkG2kbJ-b6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure()\n",
        "plt.ylabel(\"Loss (training and validation)\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,2])\n",
        "plt.plot(hist[\"loss\"])\n",
        "plt.plot(hist[\"val_loss\"])\n",
        "\n",
        "plt.figure()\n",
        "plt.ylabel(\"Accuracy (training and validation)\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,1])\n",
        "plt.plot(hist[\"acc\"])\n",
        "plt.plot(hist[\"val_acc\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfgnW2vTPBaH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V822WUUKKBSZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CAR_SAVED_MODEL = \"saved_models/cars\"\n",
        "tf.saved_model.save(model, CAR_SAVED_MODEL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rTvZJs4KFal",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load SavedModel\n",
        "\n",
        "car_model = hub.load(CAR_SAVED_MODEL)\n",
        "print(car_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZuPUCGIKIR4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get images and labels batch from validation dataset generator\n",
        "\n",
        "val_image_batch, val_label_batch = next(iter(valid_generator))\n",
        "true_label_ids = np.argmax(val_label_batch, axis=-1)\n",
        "\n",
        "print(\"Validation batch shape:\", val_image_batch.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ae-LiOawKLqz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf_model_predictions = car_model(val_image_batch)\n",
        "print(\"Prediction results shape:\", tf_model_predictions.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NR0ILKk6KOXs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert prediction results to Pandas dataframe, for better visualization\n",
        "\n",
        "tf_pred_dataframe = pd.DataFrame(tf_model_predictions.numpy())\n",
        "tf_pred_dataframe.columns = dataset_labels\n",
        "\n",
        "print(\"Prediction results for the first elements\")\n",
        "tf_pred_dataframe.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcPDhJ8aKRp2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_ids = np.argmax(tf_model_predictions, axis=-1)\n",
        "predicted_labels = dataset_labels[predicted_ids]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BihjvJ5-KUTH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print images batch and labels predictions\n",
        "\n",
        "plt.figure(figsize=(10,9))\n",
        "plt.subplots_adjust(hspace=0.5)\n",
        "for n in range(30):\n",
        "  plt.subplot(6,5,n+1)\n",
        "  plt.imshow(val_image_batch[n])\n",
        "  color = \"green\" if predicted_ids[n] == true_label_ids[n] else \"red\"\n",
        "  plt.title(predicted_labels[n].title(), color=color)\n",
        "  plt.axis('off')\n",
        "_ = plt.suptitle(\"Model predictions (green: correct, red: incorrect)\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcUE6cQOKXw0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir \"tflite_models\"\n",
        "TFLITE_MODEL = \"tflite_models/car.tflite\"\n",
        "TFLITE_QUANT_MODEL = \"tflite_models/car_quant.tflite\"\n",
        "model = tf.keras.applications.MobileNetV2(weights=\"imagenet\", input_shape=(224, 224, 3))\n",
        "run_model = tf.function(lambda x: model(x))\n",
        "concrete_func = run_model.get_concrete_function(tf.TensorSpec(model.inputs[0].shape, model.inputs[0].dtype))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vB5N4fEcKepA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert the model\n",
        "converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])\n",
        "converted_tflite_model = converter.convert()\n",
        "open(TFLITE_MODEL, \"wb\").write(converted_tflite_model)\n",
        "# Convert the model to quantized version with post-training quantization\n",
        "converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])\n",
        "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
        "tflite_quant_model = converter.convert()\n",
        "open(TFLITE_QUANT_MODEL, \"wb\").write(tflite_quant_model)\n",
        "print(\"TFLite models and their sizes:\")\n",
        "!ls \"tflite_models\" -lh"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpdvreAtOb6-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6bfpp0J8_ko",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}